
\section{Prediction in Simulink}


\subsection{Description}
This is a simulation showing the performance of the proposed prediction algorithm. It is not fine tuned in this version but allows for choice of settings corresponding to the need of a specific use case.  


\subsection{Diagram}
\begin{figure} [h]
	\centering
	\includegraphics[width=\textwidth]{../Journal/Code/SimulinkPrediction}
	\caption{Overview of simulation of the prediction algorithm.}
	\label{Fig:PredictionSimulink}
\end{figure}


\subsection{Implementation}

\subsubsection{variables}
A lot of variables, are declared in the simulation and they are not all described here. The ones described are only the tunable parameters, that should be set in the prediction problem that should be solved. The values below are used to test the performance of the simulated algorithm. 
\begin{lstlisting} [language=MATLAB]
N =200; 		%is the frame length used as memory in the prediction and the prediction order
updateRate=1;	%is the overlap in the buffer
prediction=20;  %is how far the algorithm should predict 
fs=8000; 		%is the sample frequency of the input signal 
w=hamming(N)	% could be replaced by other window functions.
\end{lstlisting}
The following sections will show the code for the individual blocks. \\
The ACF estimation estimates the autocorrelation function using the equation...
\subsubsection{ACF Estimation}
\begin{lstlisting} [language=MATLAB]
function r = fcn(x,w,updateRate,N)
persistent temp;

if isempty(temp)
	temp=zeros(N);
end

for lag = 0:N
	for n = lag+1:N
		temp(lag+1,1+N-n) = (x(n)*w(1+N-n)*x(n-lag)*w(1+N-n+lag));
	end
end
r=sum(temp')';
end
\end{lstlisting}

\subsubsection{Lenvinson Durbin}
\begin{lstlisting} [language=MATLAB]
function a = fcn(r,N)
a=levinson(r,N)';
end
\end{lstlisting}

\subsubsection{Recursive filter}
\begin{lstlisting} [language=MATLAB]
function xhat = fcn(x,a,prediction,N)
%#codegen
persistent xIn;     %buffer for input

if isempty(xIn)
	xIn=zeros(1,N+prediction);
end

% throw the oldest x away and keep indsert the newest one
xIn = [xIn(2:N) x zeros(1,prediction)]; 

for j = 1:prediction % predict "prediction" samples ahead. 
	xIn(1,N+j) = -a(2:end,1)'*fliplr(xIn(1,1+j:N-1+j))';
end
xhat = xIn(1,N+prediction);
end
\end{lstlisting}

\subsection{Test}
Prediction gain is used to evaluate the performance of the predictor. Prediction gain (PG) is given as:
\begin{equation}
	PG=10 \cdot log_{10}(\frac{\sigma^2_{input_signal}}{\sigma^2_{error}})
\end{equation} 
A PG=0 means no prediction can be achieved. A higher PG means better prediction. \\\\

Firstly the performance with different prediction orders is measured. This is the frame length parameter (N). \\ 
Here the "prediction" length is set to 42. The "updateRate" is set as the frame length under test (no overlap). When the best non overlapping frame length is found, the best overlap will be tested. The window used is the Hamming window.   
\begin{table}[H]
	\centering
	\begin{tabular}{c c} \toprule
		Prediction order 	& Prediction gain 	\\ \bottomrule
		1					& 					\\
		2					&					\\
		5					&					\\
		10					&					\\
		20					&					\\
		50					&					\\
		100					&					\\
		200					&					\\
		500					&					\\ \bottomrule
	\end{tabular}
\label{Tab:PredictionOrderGain}
\caption{Prediction order and the calculated PG}
\end{table}
It is found that a predicion order of XXX provides sufficient predicion gain. \\

Secondly different "updateRates" are evaluated with the chosen prediction order. 
\begin{table}[H]
	\centering
	\begin{tabular}{c c} \toprule
		updateRate		 	& Prediction gain 	\\ \bottomrule
		1					& 					\\
		2					&					\\
		5					&					\\
		10					&					\\
		20					&					\\
		50					&					\\
		100					&					\\ \bottomrule
	\end{tabular}
	\label{Tab:PredUpdateRateGain}
	\caption{The calculated PG for different "updateRates"}
\end{table}



