
\section{Prediction in Simulink} \label{sec:predicSimulink}

All files from this appendix can be found in folder: \\
\path{Attachment://Appendix L - Prediction in Simulink}

\subsection{Description}
This appendix shows the performance of the proposed prediction algorithm. It is not with fine tuned parameters in this version but allows for choice of settings corresponding to the need of a specific use case.  


\subsection{Diagram}
\begin{figure} [h]
	\centering
	\includegraphics[width=\textwidth]{../Journal/Code/SimulinkPrediction}
	\caption{Overview of simulation of the prediction algorithm.}
	\label{Fig:PredictionSimulink}
\end{figure}


\subsection{Variables}
A lot of variables are declared in the simulation and they are not all described here. The ones described are only the tunable parameters, that should be set in the prediction problem that should be solved. 
\begin{lstlisting} [language=MATLAB, caption=Variables.]
N; 				%is the frame length used as memory in the prediction and the prediction order
overlap;		%is the overlap in the buffer "O"
prediction; 	%is how far the algorithm should predict "P"
fs; 			%is the sample frequency of the input signal 
w=hamming(N)	% could be replaced by other window functions
M;				% is equal to N in all cases
\end{lstlisting}

\subsection{Functions}
The following sections will show the code for the individual blocks. 



\subsubsection{ACF Estimation}
The ACF estimation estimates the ACF using \autoref{eq:Appnonrecursive}
\begin{lstlisting} [language=MATLAB, caption=ACF estimation.]
function r = fcn(x,w,updateRate,N)
persistent temp;

if isempty(temp)
	temp=zeros(N);
end

for lag = 0:N
	for n = lag+1:N
		temp(lag+1,1+N-n) = (x(n)*w(1+N-n)*x(n-lag)*w(1+N-n+lag));
	end
end
r=sum(temp')';
end
\end{lstlisting}

The result of the ACF estimation is compared to the Matlab xcorr function in \autoref{fig:ACFTest} with no difference in results. The window used is a rectangular window, so the calculation of xcorr is mirrored.  
\begin{figure}[H]
	\centering
	\tikzsetnextfilename{ACFtest}	
	\input{figures/PredictionAppendix/ACFEst.tex}
	\caption{Implemented ACF estimator (orange) compared with Matlab build in xcorr (blue) - Identical results.}
	\label{fig:ACFTest}
\end{figure}
 

\subsubsection{Levinson-Durbin}
\begin{lstlisting} [language=MATLAB, caption=Levinson-Durbin. ]
function a = LevinsonDurbin(r, M)
% r      ACF It's a Coloumn input
% M      Prediction order
% r0     ACF at lag 0
% r      ACF from lag 1 to m+1. It's like a Coloumstyle input
% m      Prediction order
% a      LP coefficients
r0=r(1);
r=r(2:end);

% INITIALIZATION - What do we know when we start?
a = zeros(M+1,1);       % Define the coloumn we are calculating
a(1) = 1;               % The zero order prediction
E = r0;                 % Error at lag 0 is the r0 in the ACF
a(2) = -r(1) / r0;      % The first order prediction
k(1) = a(2);            % k values are reflection coefficients
q = r(1);               % The Q-Value


% RECURSION - Moving on from the basics
for i = 1:M-1
	E = E + ( q * k(i) );                   
	q = r(i+1);
	q = q + sum( r( 1:i) .* a(i+1:-1:2) );
	k(i+1) = -q / E;
	tmp (1:i) = k(i+1) .* a(i+1:-1:2) ;
	a( 2:i+1) = a( 2:i+1) + tmp(1:i)';
	a(i+2) = k(i+1) ;
E = E + ( q * k(i) );                   
q = r(i+1);
q = q + sum( r( 1:i) .* a(i+1:-1:2) );
k(i+1) = -q / E;
tmp (1:i) = k(i+1) .* a(i+1:-1:2) ;
a( 2:i+1) = a( 2:i+1) + tmp(1:i)';
a(i+2) = k(i+1) ;
end
% Same output syntax as Matlab
a = a';
\end{lstlisting}
In \autoref{fig:LDTest} the result of the Levinson-Durbin is compared to the Matlab function, "levinson", with no difference in results.   
\begin{figure}[H]
	\centering
	\tikzsetnextfilename{LDtest}	
	\input{figures/PredictionAppendix/levDurbTest.tex}
	\caption{Implemented Levinson-Durbin (orange) compared with Matlab build in function (blue) - Identical results.}
	\label{fig:LDTest}
\end{figure}

\subsubsection{Recursive filter}
\begin{lstlisting} [language=MATLAB, caption=Recursive filter -- Wiener filter.]
function xhat = fcn(x,a,prediction,N)
%#codegen
persistent xIn;     %buffer for input

if isempty(xIn)
	xIn=zeros(1,N+prediction);
end

% throw the oldest x away and keep indsert the newest one
xIn = [xIn(2:N) x zeros(1,prediction)]; 

for j = 1:prediction % predict "prediction" samples ahead. 
	xIn(1,N+j) = -a(2:end,1)'*fliplr(xIn(1,1+j:N-1+j))';
end
xhat = xIn(1,N+prediction);
end
\end{lstlisting}

\subsection{Test}

\subsubsection{Testing the predictor for different $f_s$ -- Non automated test}

When testing the predictor for different $f_s$ automated testing can not be used, as the audio file used by the predictor has to be changed to the version with the correct sample rate. \\ 
In the "Init.m" file $N$ should be equal to $f_s$/N, $O=0$ and $P=1$. The following steps should be taken for each $f_s$ under test:
\begin{itemize}
	\item Choose the correct audio file in Simulink. 
	\item Set the $f_s$ parameter in "Init.m". 
\end{itemize}
The results are stored in different files automatically, and are shown in \autoref{tb:fsPredictApp}.

\begin{table}[H]
\centering
\begin{tabular}{|l|c|c|c|c|c|c|}
	\hline
	$f_s$ {[}$k$Hz{]} & 8 & 16 & 24 & 48 & 96 & 192 \\ \hline 
	$N$ {[}samples{]} & 100 & 200 & 300 & 600 & 1200 & 2400 \\ \hline 
	PG {[}dB{]} & 13.5 & 15.9 & 14.7 & 20.8 & 35.0 & 43.8 \\ \hline
\end{tabular}
\caption{$PG$ as a function of $f_S$. Parameters for the simulation are $O=0$ and $P=1$.}
\label{tb:fsPredictApp}
\end{table}  
 
\subsubsection{Testing the predictor for different $N$ \& $O$ -- Automated test}
Here the automated test set-up described in \autoref{sec:SimulinkAuto} is used.\\\\ 
The PG with different prediction orders is measured. This is the frame length parameter ($N$). The overlap parameter ($O$) is also varied. 
Here the $P$ is set to 43. $N$ is varied from 100-3000 in steps of 100. Overlap, $O$ is varied from 0 to N-100. The used window is the Hamming window. The results are plotted using the surf function in Matlab, and the viewing angle is set to "from above" resulting in a 2D plot. It should be noted that the measured points are the crossings of the black lines and not the coloured squares. %The mesh() plot could be used to avoid this, if a less readable plot could be accepted. 

\begin{figure}[H]
	\centering
	\tikzsetnextfilename{HammingNOP43App}	
	\input{figures/Articleillustrations/HammingNOP43.tex}
	\caption{$PG$ as a function of different $N$ and $O$ with $P=43$.}
	\label{fig:Predict43App}
\end{figure}

The same experiment is performed with $P=10$.
\begin{figure}[H]
	\centering
	\tikzsetnextfilename{HammingNOP10App}	
	\input{figures/Articleillustrations/HammingNOP10.tex}
	\caption{$PG$ as a function of different $N$ and $O$ with $P=10$.}
	\label{fig:Predict10App}
\end{figure}


\subsubsection{Testing the predictor for different $P$ -- Automated test}
Using $N=1200$ and $O=1100$ the PG of the predictor for different $P$ is determined. 
\begin{figure}[H]
	\centering
	\tikzsetnextfilename{PvarApp}	
	\input{figures/Articleillustrations/PvarAppendix.tex}
	\caption{$PG$ as a function of $P$. $N=1200$ and $O=1100$.}
	\label{fig:PredictPApp}
\end{figure}

\subsubsection{Testing the predictor for different $M$ -- Automated test}
Using $N=1200$ and $O=1100$ the PG of the predictor for different M is determined. The test is made with both $P=1$ and $P=10$. 
\begin{figure}[H]
	\centering
	\tikzsetnextfilename{MvarApp}	
	\input{figures/PredictionAppendix/Mvar.tex}
	\caption{$PG$ as a function of $M$ for $P=1$ (blue) and $P=10$ (orange).  $N=1200$ and $O=1100$.}
	\label{fig:PredictMApp}
\end{figure}
For $P=1$ a low $M$ can be used. When the filter is cascaded to predict 10 samples $M=N$ is required. 

\subsection{Conclusion}
The optimal parameters for $P=10$ have been determined to $N=1200$ and $O=1100$. Furthermore it has been shown that $M=N$ is required if $P=10$. 
