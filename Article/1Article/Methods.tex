%% Introduction
\section{Methods} \label{sec:methods}
\subsection{Feedforward ANC using FXLMS}
%The adaptive feedforward ANC system is shown on \autoref{fig:ANCFeedforward}


The system in \autoref{fig:ANCFeedforward} outputs a control signal $y(t)$, which ideally is a counter-phase signal ofs the noise. The counter-phase signal is generated by filtering the reference signal $x[n]$ using a control filter, consisting of adaptive coefficients $\bar{b}$. $\bar{b}$ representing the inverse of the transfer function from the reference microphone to the headphone loudspeaker (HP). Thereby ensuring that the signal $y(t)$ is the inverse of $x(t)$. $\bar{b}$ is adapted using the FXLMS algorithm. This adaption ensures that the optimum counter-phase signal is output even if the transfer function changes e.g when changing the angle of incident of the noise. The FXLMS algorithm receives the filtered reference signal $f[n]$ along with the error signal $e[n]$. The filtered reference signal is used in combination with the error signal to determine new optimal coefficients for the control filter, this is shown in equation \ref{eq:FXLMS}. 



\begin{figure}[H]
	\centering
	%\includegraphics[width=1\columnwidth]{figures/ArticleIllustrations/ANCFeedForward}
		\tikzsetnextfilename{ANCFeedForward}
		\input{figures/ArticleIllustrations/ANCFeedForward.tex}
	\caption{Block diagram of adaptive feedforward ANC system. Expansion of DSP (4) from \autoref{fig:SystemOverview}.}
	\label{fig:ANCFeedforward}
\end{figure}

%The signals from (1) and (3) from \autoref{fig:ANCFeedforward} are converted to the digital domain using an ADC and anti-aliasing (AA) filters before processing. When processed, the output $y[n]$ is reconstructed using a DAC. \\\\

%\begin{figure}[H]
%	\centering
%	\includegraphics[width=1\columnwidth]{figures/ArticleIllustrations/ANCFeedForward}
%	\caption{Adaptive feedforward ANC system}
%	\label{fig:ANCFeedforward}
%\end{figure}

The Control Filter, shown in \autoref{eq:Output}, has an order of 960 taps to represent frequencies down to 50 Hz with $f_s = 48$ $k$Hz. 
%NO fucks given!
\begin{equation}\label{eq:Output}
y[n]=\sum_{j=0}^{L-1}b_j[n]x[n-j]
\end{equation}
Where: $b_j[n]$ are the weight coefficients written as  $b_j[n]=[b_0[n],b_1[n], \dotsc, b_{L-1}[n]]^T$. The control filter coefficients are updated using the FXLMS method shown in \autoref{eq:FXLMS}.
\begin{equation}\label{eq:FXLMS}
b_j[n+1] = b_j[n] - 2\mu e[n]f[n-j]
\end{equation}
Where: $\mu$ is the convergence factor, $e[n]$ is the error and $f[n]$ is the reference signal convolved with the Cancellation Path (CP) shown in \autoref{eq:CP}.
\begin{equation}\label{eq:CP}
f[n]=\sum_{j=0}^{L-1}c_jx[n-j]
\end{equation}
Where: $c_j$ is the coefficient of a measured transfer-function from the headphone loudspeaker to the error microphone in the ear of a Head and Torso Simulator (HATS). In the literature \cite{Hansen} the CP is adaptively adjusted, but it is assumed constant because the position of the headphone does not change while testing on a HATS. 


%When implementing the system, delays exist due to the anti-aliasing and reconstruction filters. The delays of the system exceeds the propagation time of sound from the reference microphone to the headphone loudspeaker resulting in poor performance. Therefore an LP-algorithm is proposed to predict future samples in order to decrease the effect of the time delays.
\subsection{Measuring HP and CP Transfer Functions}
The two transfer functions HP and CP were measured on a set of Beyerdynamic DT 770 Headphones in an anechoic chamber using a HATS. The setup is similar to \autoref{fig:SystemOverview} except the DSP (4) is replaced by a soundcard. When measuring HP a small microphone (spmMic) is placed by the headphone loudspeaker (2) and a loudspeaker is placed 1.6 m from the center of the HATS at 0\textdegree angle of incidence.  

\begin{figure}[H]
	\centering
	\tikzsetnextfilename{CancellationPathImpulseResponseCompareCP}
	%\input{figures/CancellationPath_MATLAB_Figures/CancellationPathImpulseResponseCompare.tex}
	\input{figures/ArticleIllustrations/compfilterCP.tex}
	\caption{Comparison of the cancellation path frequency response of 960 coefficients vs. 288,768 coefficients.}
	\label{CancellationPathImpulseResponseCompare}
\end{figure}
   
The measurement of HP is done by playing a logarithmic chirp (50 Hz -- 24 $k$Hz) with the loudspeaker and recording using the reference microphone (1) and spmMic.  
\\\\
The measurement of CP is done by playing a logarithmic chirp (50 Hz -- 24 $k$Hz) with the headphone loudspeaker (2) and recording using the error microphone (3) and a loopback.
\\\\
The recordings are used to calculate the transfer functions using the cross correlations shown in \autoref{Eq:Xcorr method} \cite{TutorialMeasurementPowerSpectra}.   
\begin{equation}
H(f)=\dfrac{\mathscr{F}(y(t)\ast x(-t))} {\mathscr{F}(x(t)\ast x(-t))}
\label{Eq:Xcorr method}
\end{equation}

\begin{figure}[H]
	\centering
	\tikzsetnextfilename{CancellationPathImpulseResponseCompareHP}
	%\input{figures/CancellationPath_MATLAB_Figures/CancellationPathImpulseResponseCompare.tex}
	\input{figures/ArticleIllustrations/compfilterHP.tex}
	\caption{Comparison of the cancellation path frequency response of 960 coefficients vs. 288,768 coefficients.}
	\label{CancellationPathImpulseResponseCompare}
\end{figure}

\subsection{Characteristics of Speech}
Speech is characterized quasiperiodic signal which can be split into two main classes; voiced and unvoiced. Voiced sounds are characterized by a strong periodicity, with the fundamental frequency referred to as the pitch frequency (50 Hz -- 500 Hz). Unvoiced sounds are characterized as stochastic. Speech is a non stationary signal and can only be assumed Wide Sense Stationary (WSS) for periods of 20 $m$s -- 30 $m$s \cite{Speech}. 

\subsection{Linear Prediction of Speech}
The outline of the prediction system is shown in figure \ref{fig:LinearPredictionOverview}. The system predicts $\hat{x}[n+P]$ by adapting linear prediction coefficients (LPCs) $\hat{\bar{a}}$, in a Wiener filter, determined using a framebased Auto Correlation Function (ACF) estimation $\hat{r}_x[l]$ \cite{LinearPrediction}.   

\begin{figure}[H]
	\centering
	\tikzsetnextfilename{WienerHopf}
	\input{figures/ArticleIllustrations/WienerHopf.tex}
	%\includegraphics[width=\columnwidth]{figures/ArticleIllustrations/WienerHopf}
	\caption{Block diagram of linear prediction system.}
	\label{fig:LinearPredictionOverview}
\end{figure}


The ACF is estimated by nonrecursive estimation, shown in \autoref{eq:nonrecursive}, with framelength N. The nonrecursive estimation relies on a well defined window in order to increase the periodicity of the ACF. This is done by weighting the center of the frame highest, assuming highest periodicity in the center of a frame. Therefore a Hamming window, w is applied being one of the most widely used in speech encoding \cite{LinearPrediction}. Furthermore overlapping, $O$ can be used to increase the update rate of the ACF without having a small framelength.  
\begin{equation}\label{eq:nonrecursive}
%%r_x[l,m] = \sum^{m}_{n=m-N+1+\left| l\right|} x_l[n]w_l[m-n]
\hat{r}_x[l] = \sum^{N}_{n=\left| l\right|} x_l[n]w_l[N-n]
\end{equation}
%\begin{multline}\label{eq:nonrecursive}
%R[l,m] = \sum^{m}_{n=m-N+1+\left| l\right|} \\ x[n]w[m-n] x[n-\left| l\right|]w[m-n+\left| l\right|]
%\end{multline}
%\begin{equation}
%R[l,m]=\sum^{m}_{n=m-N+1+\left| l\right|}x[n]w[m-n] x[n-\left| l\right|]w[m-n+\left| l\right|]
%\end{equation}
Where: l is the lag, $x_l[n]=x[n]x[n-l]$ and $w_l[n]=w[n]w[n+l]$. The LPCs are determined using \autoref{eq:normal}, known as the Wiener-Hopf equation.
\begin{equation}\label{eq:normal}
\hat{R}  \bar{a} = -\bar{\hat{r}}_x
\end{equation}
Where: $\hat{R}$ is the covariance matrix $\hat{C}_{xx}$, $\bar{\hat{a}}$ is the LPCs $\bar{\hat{a}} = [\hat{a}_0 , \hat{a}_1, \dotsc, \hat{a}_{N-1}]^T$ and $\bar{\hat{r}}_x$ is the ACF, $\bar{\hat{r}}_x = [\hat{r}_x[0] , \hat{r}_x[1], \dotsc, \hat{r}_x[N-1]]^T$. \autoref{eq:normal} can be rewritten as shown in \autoref{eq:normal2} yielding the LPCs directly.  
 \begin{equation}\label{eq:normal2}
\bar{\hat{a}} = \hat{-R^{-1}} \bar{\hat{r}}_x
\end{equation}
Calculating $\hat{R}^{-1}$ is computationally heavy. Therefore to estimate the LPCs the Levinson-Durbin method is used \cite{LinearPrediction}. Prediction using Wiener filtering, shown in equation \ref{eq:Predictor}, can then be applied to the current frame for prediction of the next frame. To decrease the computational cost only LPCs with an impactfull magnitude should be used \cite{Speech}. 
%These are the first 50 -- 400 LPCs and the LPCs located at the respective pitch frequency of the speech \cite{Speech}.      

\begin{equation}\label{eq:Predictor}
\hat{x}[n+p] =- \sum^{M-1}_{i=1}\hat{a}_i[n]x[(n+p)-i]
\end{equation}

Using equation \ref{eq:Predictor} in cascade $\hat{x}[n+2]$ is estimated using $\hat{x}[n+1]$ and $x[n]$ up until $\hat{x}[n+P]$. 


\subsection{Prediction Gain}
For the purpose of testing the LP's Prediction Gain (PG) shown in \autoref{eq:PG} will be used. 
\begin{equation}\label{eq:PG}
PG = 10 log_{10}\bigg(\frac{\sigma^2_x}{\sigma^2_\varepsilon}\bigg) = 10 log_{10}\bigg(\frac{E\{x^2[n]\}}{E\{\varepsilon^2[n]\}}\bigg)
\end{equation}
Where: PG is the ratio between the variance of the input signal $x[n]$ and the variance of the prediction error, $\varepsilon$ measured in dB. The higher the PG the better the prediction is.

\subsection{Computational cost of LP}
The computational cost of prediction is given by minimum \autoref{eq:Cost}
\begin{equation}\label{eq:Cost}
N_{Cost} = \frac{2\cdot N^2}{N-O}+\frac{N^2}{N-O}+P\cdot N   
\end{equation}
Where the first term is from the ACF estimation, the second term is from the Levinson Durbin and the third term is the wiener filter. 

\subsection{Feedforward LP FXLMS}
The adaptive ANC system combined with the predictor is shown on \autoref{fig:LPFXLMS}. The predictor will be inserted before the ANC system. The predictor need to compensate for both the sampling and reconstruction delay, which are assumed to have the same delay ($i=\frac{P}{2}$).   

\begin{figure}[H]
	\centering
	\tikzsetnextfilename{CombinedSystem2}
	\input{figures/ArticleIllustrations/CombinedSystem.tex}
	\caption{Block diagram of combined system of LP and feedforward FXLMS.}
	\label{fig:LPFXLMS}
\end{figure}

The adaptive ANC inputs the predicted input $\hat{x}[n+P]$ and the measured input $x[n]$, into the control filter and the CP. This will expand \autoref{eq:Output} and \autoref{eq:CP} into \autoref{eq:ControlExpanded} and \autoref{eq:CPExpanded} respectively.   

\begin{equation}\label{eq:ControlExpanded}
y[n+P]=\sum^{P-1}_{j=0}b_j[n]\hat{x}[(n+P)-j]+\sum^{L-1}_{j=P}b_j[n]x[(n+P)-j]
\end{equation}

\begin{equation}\label{eq:CPExpanded}
f[n+P]=\sum^{P-1}_{j=0}c_j\hat{x}[(n+P)-j]+\sum^{L-1}_{j=P}c_jx[(n+P)-j]
\end{equation}

The reasoning behind using both $\hat{x}[n+P]$ and $x[n]$ is that it will give a more precise result, than if only $\hat{x}[n+P]$ was used in the ANC system. This is because less predicted samples will be input into the ANC system which should result in a more precise $y[n+P]$. The input $e[n]$ is not predicted because the proposed solution of delaying $f[n+P]$ $i$ times, is easier. This results in $f[n+\frac{P}{2}]$ which coincides with $e[n+\frac{P}{2}]$ as shown on \autoref{fig:LPFXLMS}. Delaying instead of predicting will yield a slower reaction time however it is much less computationally heavy.       

%$\hat{x}[n+P]$ and $x[n]$ are used in combination where known samples are used 