\section{Linear Prediction}
Linear Prediction (LP) is proposed in order to compensate for the delay introduced by sampling and reconstructing acoustical signals. The delays have high impact on the performance of an ANC system. \\
The proposed predictor uses Wiener filtering to predict the next sample based on the autocorrelation (ACF) of some previous samples. The prediction algorithm is then coupled in cascade in order to predict multiple samples. 

\begin{figure}[H]
	\centering
	\tikzsetnextfilename{WienerHopf}
	\input{figures/ArticleIllustrations/WienerHopf.tex}
	%\includegraphics[width=\columnwidth]{figures/ArticleIllustrations/WienerHopf}
	\caption{Block diagram of linear prediction system.}
	\label{fig:APPLinearPredictionOverview}
\end{figure}
The system predicts $\hat{x}[n+P]$ by adapting linear prediction coefficients $\hat{\bar{a}}$, in a Wiener filter, determined using a framebased Auto Correlation Function (ACF) $\hat{r}_x[l]$ \cite{LinearPrediction}.

\begin{itemize} 
	\item $N$ is the framelength, that is the amount of previous samples stored and used for predicting the next sample. $\bar{x}$ in \autoref{fig:APPLinearPredictionOverview} has size $N$.
	\item $M$ is the order of the predictor, that is the amount of coefficients used for predicting the next sample. $\hat{\bar{a}}$ in \autoref{fig:APPLinearPredictionOverview} has size $M$.
	\item $O$ is the overlap, that is the amount of samples to be reused, when calculating the new ACF. A new ACF and new LPCs are estimated for each $N-O$ samples.
	\item $P$ determines the how many samples will be predicted. 
	\item $W$ is a window used for weighting the samples in the current frame when calculating the ACF. 
\end{itemize}


\subsection{Auto Correlation estimation}
The full autocorrelation would be an infinite time series, which would be impossible to calculate and it would not be useful as speech is not Wide Sense Stationary through infinite time. The short time stationarity of speech is used by only estimating the ACF for a short time frame determined by N/fs. The ACF is estimated using \autoref{eq:Appnonrecursive}.
\begin{equation}\label{eq:Appnonrecursive}
%%r_x[l,m] = \sum^{m}_{n=m-N+1+\left| l\right|} x_l[n]w_l[m-n]
\hat{r}_x[l] = \sum^{N}_{n=\left| l\right|} x_l[n]w_l[N-n]
\end{equation}
Where: l is the lag, $x_l[n]=x[n]x[n-l]$ and $w_l[n]=w[n]w[n+l]$. w is a window that can be applied to emphasize ?SOMETHING?. Some experimenting has been made using different windows. It was found that a Hamming window yielded best performance, but a rectangular window yielded almost similar results while saving a computations, as multiplying all samples by one can be omitted. A Barnwell window is proposed by \cite{Speech}, but has been found to yield poorer results than both other windows.   


check the where - also in article\\\\
We claim something about 50-400 LPC in article\\
Is the WF equation not allready cascaded? Or not really. A sum over p is missing?\\
We lack a new CP\\
We lack a journal on measuring performance of ANC headphones\\
We lack HP and CP in article.\\


\subsection{ Wiener Hopf - finding the Linear Prediction Coefficients}
 The Linear Prediction Coefficients (LPCs) are determined using \autoref{eq:normal}, known as the Wiener-Hopf equation.
\begin{equation}\label{eq:normal}
\hat{R}  \bar{a} = -\bar{\hat{r}}_x
\end{equation}
Where: $\hat{R}$ is the covariance matrix $\hat{C}_{xx}$, $\bar{\hat{a}}$ is the LPCs $\bar{\hat{a}} = [\hat{a}_0 , \hat{a}_1, \dotsc, \hat{a}_{N-1}]^T$ and $\bar{\hat{r}}_x$ is the ACF, $\bar{\hat{r}}_x = [\hat{r}_x[1] , \hat{r}_x[2], \dotsc, \hat{r}_x[N]]^T$. \autoref{eq:normal} can be rewritten as shown in \autoref{eq:normal2} yielding the LPCs directly.  
\begin{equation}\label{eq:normal2}
\bar{\hat{a}} = \hat{-R^{-1}} \bar{\hat{r}}_x
\end{equation}
Calculating $\hat{R}^{-1}$ is computationally heavy, therefore to estimate the LPCs the Levinson-Durbin method is used. 

Write HERE Oliver - levinson durbin\\



\subsection{Wiener filter}
A Wiener filter is used in cascade, where $\hat{x}[n+2]$ is estimated using $\hat{x}[n+1]$ and $x[n]$ up until $\hat{x}[n+P]$. 
\begin{equation}\label{eq:AppPredictor}
\hat{x}[n+p] =- \sum^{M-1}_{i=1}\hat{a}_i[n]x[(n+p)-i]
\end{equation}
The Wiener filter resembles an FIR filter, where the previous inputs are used in combination with the LPCs to predict the next sample. 

\subsection{Prediction Gain}
The Prediction Gain (PG) is an objective measure of the performance of a predictor measured in dB. 
\begin{equation}\label{eq:App_PG}
PG = 10 log_{10}\bigg(\frac{\sigma^2_x}{\sigma^2_\varepsilon}\bigg) = 10 log_{10}\bigg(\frac{E\{x^2[n]\}}{E\{\varepsilon^2[n]\}}\bigg)
\end{equation}
As seen in \autoref{eq:App_PG} the PG is calculated based on a ratio between the variance of the signal to be predicted $\sigma^2_x$ and the variance of the error of the predictor $\sigma^2_\varepsilon$. The PG value yields an estimate of the performance of the predictor, however it is necessary to also listen to the predicted signal, as it might be distorted. PG is used as the performance indicator, while searching for optimum parameters for the predictor.  


%\begin{figure}[H]
%	\tikzsetnextfilename{BasisCompare}
%	\input{../Article/2Appendix/LPFigs/BasisCompare(fig).tex}
%	\label{Fig:BasisCompare}
%	\caption{Text here.}
%\end{figure}

%\begin{figure}[H]
%	\tikzsetnextfilename{LPCompare}
%	\input{../Article/2Appendix/LPFigs/LPCompare(fig).tex}
%	\label{Fig:LPCompare}
%	\caption{Text here.}
%\end{figure}